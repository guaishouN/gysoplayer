### 目录

了解音频解码功能和流程

了解视频解码功能和流程

如何解决音视频同步问题

[工程项目地址](https://gitee.com/guaishoun/ffmpegfoundation.git)

##### 一些阅读资料

声音（模拟信号）-->采样（离散信号）->量化（数字信号）-->编码（音频文件）

20Hz--20kHz

量化格式-sampleformat -16bit

采样率-samplerate-44100

声道-channel-2

比特率（bitRate、码率）=量化格式\*采样率\*声道

WAV无损压缩

MP3

AAC用于视频中的音频编码

Ogg

### 上课内容

工具->编码信息->编解码器 可以看到视频信息

流0 视频流  h264编码格式 mpeg是音视频统一封装格式

流2 音频流 aac

流3 字幕流

h264视频+aac音频 =>Mpeg4 ->.rmvb

yuv---编码封装-->rmb--解封装--->音频流视频流（还是压缩的）--解码--->显示

![编解码过程图](..\..\..\images\截图\音视频处理流程图.PNG)

你等我，我等你的过程叫做音视频同步

### 关键类

![](..\..\..\images\截图\ffmpeg关键类1.PNG)

![](..\..\..\images\截图\ffmpeg关键类2.PNG)

#### 总体流程

![](..\..\..\images\其他\ffmpeg解码流程.jpg)

### 编码过程

**gradle**

在abiFilters “armeabi-v7a”

**cmake**

查看NDK版本，去到NDK目录有个source.properties

```CMAKE
file(CLOB SOURCE src/main/cpp/*.cpp)

add_library(
	wangyiplayer
	Shared
	&{SOURCE}
)
include头文件
avfilter avformat avcodec avutil swresample swscale
set(my_lib_path ${CMAKE_SOURCE_DIR}/libs/${android_abi})
set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -L${my_lib_path}")
target_link_libraries( 
	#ndk-bundle/platforms/android-23/arch-arm/usr/lib	
	android
	z
	OpenSLES
  )
```

**cpp**

```c
extern "C"{
	include "ffmepg头文件"
}
```

**xml**

添加surfaceview到布局中

SeekBar进度控制

button 打开

**java**

***mainactivty全屏***

```java
getwindow().setFlags(WindowManager.LayoutParams.FLAGS_KEEP_SCREEN_ON,WindowManager.LayoutParams.FLAG_KEEP_SCREEN_ON);

Wangyipalyer player=new WangyiPlayer();

player.setSurfaceView(surfaceView);
```





**WangyiPlayer**

```java
创建WangyiPlayer implements SurfaceHolder.Callback
在setSurfaceView {  
if(!surfacehodler= null)
	surfaceholder.removeCallback(this)	
}
在surfaceChanged{
	this.surfaceholder = surfaceholder
}
void start(){
    native(path,surfaceHolder.getsurface())
}
```

**native-lib.cpp**

```C
//FFmpeg 视频绘制 音频播放
//注意头文件要放在extern"C"中
// 初始化网络 ffmpeg不仅可以播放本地视频 它也可以播放网络视频
avformat_network_init();
//第一个上下文 AVFormatContext 主要获取音频流视频流字幕流
//第二个上下文 AVCodecContext 视频流获取宽高解码器（AVCodec）->yuv数据
//第三个上下文-SwsContext 绘制上下文 将yuv数据绘制到surfaceView
AVFormatContext * formatContext = avformat_alloc_context();
AVDictionary *opts =NULL;
//p1 AVDictionary (if null then new())  p2 key p3 value p4 flag=0
av_dic_set(&opts,"timeout","3000000")//us
//文件打开控制 p1上下文  url本地或网络 p3 空 AVDAVDictionary
int ret = avformat_open_input(&formatContext,path,NULL,&opts);
if(ret){
    return
}
//视频流
AVformat_find_stream_info(formatContext,NULL)

 int video_stream_idx=-1
for(int i= 0;i<formatContext->nb_streams;++i){
    if(formatContext->stream[i]->codecpar->codec_type ==AVMEDIA_TYPE_VIDEO){
        video_stream_idx = i;
        break;
    }
}
//视频流的解码参数
AVCodecParameters *dedecpar = formatContext->streams[vidio_stream_idx]->codecpar;
//解码器h264 像java的策略模式 key-id
//context.getLayoutInflater() hashmap
AVCodec *dec = avcodec_find_decoder(codecpar->codec_id);
//解码器的上下文 3代表最新
AVCodecContext *codecContext = avcodec_alloc_context3(dec)
//将解码器参数copy到解码器上下文
 avcodec_parameters_to_context(codecContext,codecpar);
//打开解码器
AVcodec_open2(codecContext,dec,NULL);
//解码 malloc()  new AVPacket
//yuv数据看不到 被封装在AVPacket里面找 有个paket队列，要从队列中取一个空的packet
AVPacket *packet = av_packet_alloc();
//从视频流中读取数据包 0 ok <0结束或错误
//av_packet_alloc一个packet->解码器av_read_frame取一个内容到packet->avcodec_send_packet取出packet
//错误码 AVERROR(EAGAIN) 队列满要先receive; AVERROR_EOF 队列空先发送再取；AVERROR(EINVAL) 没打开或者需要刷新
//转换上下文 sws_getContext
SwsContext *swsContext = sws_getContext(codecContext->width,codecContext->heigth,codecContext->pix_fmt,codecContext->width,codecContext->heigth,AV_PIX_FMT_RGBA,SWS_XX,0);

//窗体
//内部 缓冲区 buffer1080*1920  内存的拷贝 一行一行拷贝
ANativeWindow * nativeWindow = ANativeWindow_fromSurface(env,surface);
ANativeWindow_setBuffersGeometry(nativeWindow,codecContext->width,codecContext->height,WINDOW_FORMAT_RGBA_8888);
//

while(av_read_frame(formatContext,packet)>=0){
    avcodec_send_packet(codecCOntext,packet);
    AVFrame *frame = av_frame_alloc();
    ret=avcodex_receive_frame(condecContext,frame);
    if(ret == AVERROR(EAGAIN)){
        continue;
    }else if(ret<0){
        break;
    }
    //接收的容器
    uint8_t *dst_data[4];    
    //每一行的首地址
    int dst_linesize[4];
    av_image_alloc(dst_data,dst_linesize,codecContext->width,codecContext->height,AV_PIX_FMT_RGB,1);//最后一个参数表示左对齐
    //绘制 avframe-->rgba
    sws_scale(swsContext,frame->data,frame->linesize,0,frame->height,dst_data,dst_linesize);
    //获取窗体缓冲区 outBuffer
    ANativeWIndow_lock(nativeWindow,&outBuffer,NULL);//第三个参数表示限制
    //渲染
    for(int i=0;i<outBuffer.height;++i){
        //内存拷贝，一行一行拷贝
        memcp(firstWindown+i*desStride,src_data+i*src_linesize,6);  
    } 
    ANativeWIndow_unlockAndPost(nativeWindow);
    usleep(1000*16);
    av_frame_free(&frame);
}
//原来的视频 p12输入宽高 p3输入编码格式
//输出p45输出宽高 p6输出的编码格式 RGBA
//flags 
sws_getContext  

```



## 解码音频流

```C
采样频率：每秒钟的采样样本数量叫做采样频率，采样率越高越接近原来波形，保真度越高
采样位数：可以理解为采集卡处理声音的解析度，一般16位。用来表达每个样本的大小。

步骤同样是：
1 总上下文
2 遍历流
3 解码器上下文
4 获取到解码器
5 流中读取packet
6 paket转换成frame
7 统一转换成可显示格式
8 输出响应设备

SwsContext ->vedio
SwrContext ->audio
//输入声音要配置三个参数 采集频率 采样位数 通道数
AVSampleFormat in_sample = codecContext->sample_fmt;
int in_sample_rate = codecContext->sample_rate;
unit64_t in_ch_layout = codecContext->channel_layout;
//输出解码声音固定
AVSampleFormat out_sample=AV_SAMPLE_FMT_S16
int out_sample_rate = 44100;
unit64_t out_ch_layout = AV_CH_LAYOUT_STEREO;
swr_alloc_set_opt(......);
//还得初始化转换器及其他默认参数
swr_init(swrContext)
unit8_t *outbuffer = (unit8_t *)(av_malloc(2 * 44100));
FILE *fp_pcm = fopen(output,"wb");
//读取包 压缩数据
AVPacket *packet=av_packet_alloc();
int count=0
//设置音频缓冲区间 16bit 44100 PCM数据
while(av_read_frame(formatContext, packet)>0){
	avcodec_send_packet(codecContext,packet);
	//解压缩数据 未压缩
	AVFrame *frame =av_frame_alloc();
	int ret = avcodec_receive_frame(codecContext,frame);
	if(ret == AVERROR(EAGAIN))
		continue
	else if(ret<0){
		LOGE("解码完成");
		break;
	}
	
	if(packet->stream_index!=audio_stream_idx){
		continue;
	}
	LOGE("正在解码%d"，count++);
	//统一格式
	swr_convert(swrContext,&out_buffer,2*44100,(const unit8_t **)frame->data,frame->nb_samples);
	//输出到file
	int out_channel_nb = av_get_channel_layout_nb_channels(out_ch_layout);
	//对齐 缓冲区的大小
	int out_buffer_size = av_samples_get_buffet_size(NULL,2,frame->nb_samples,out_sample,1);
	fwrite(out_buffer,1,out_buffer_size,fp_pcm);	
}
fclose(fp_pcm)
av_free(out_buffer);
swr_free(&swrContext);
avcodec_close(codecContext);
avformat_close_input(&&formatContext);

env->ReleaseStringUTFChars(input_,input);
env->ReleaseStringUTFChars(output_,output);
```













